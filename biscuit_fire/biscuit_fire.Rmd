---
title: "biscuit_fire"
author: "ddxbugs"
date: "2024-02-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<h5>Oregon Biscuit Fire 2002</h5>

<h6>When wildfires ravage forests, the timber industry argues that logging the burned trees enhances forest recovery; the EPA argues the opposite. The 2002 Biscuit Fire in southwest Oregon provided a test case.  Researchers selected 16 fire-affected plots in 2004, before any logging was done and counted tree seedlings along a randomly located transect pattern in each plot.  They returned in 2005, after nine of the plots had been logged, and counted the tree seedlings along the same transects.  The percent of seedlings lost from 2004 to 2005 is recorded in the file logging.csv for logged (L) and unlogged (U) plots:</h6>

<h6>Test the EPA’s assertion (and thus the opposite of the logging industries assertion) that logging actually increases the percentage of seedlings lost from 2004 to 2005.</h6>

<ul>
<li>Perform a complete analysis using a rank sum test in SAS. (Logging data).</li>
<li>Verify the p-value and confidence interval by running the rank sum test in R (using R function Wilcox.test).</li>
<li>Finally, perform a permutation test for the difference of means.  As with all ”tests”, this should include a clear conclusion written in the context of the problem and in terms understandable by a client (although it should also include a pvalue.)</li>
</ul>

<h5>Import data set</h5>
```{r}
library(dplyr)
loggingDF <- read.csv("Logging.csv", header=TRUE)
loggingDF

```
<h5>Tidy & Transform data set</h5>
```{r}
loggingDF %>% group_by(Action) %>% summarize(
  count <- n(),
  median <- median(PercentLost, na.rm=TRUE),
  IQR <- IQR(PercentLost, na.rm=TRUE)
)

actionU <- loggingDF %>% filter(Action == "U")
actionL <- loggingDF %>% filter(Action == "L")
```
<h5>Hypothesis Testing</h5>

<h6>H~0~: median(logged) = median(unlogged)</h6>

<h6>H~A~: median(logged) $\neq$ median(unlogged)</h6>
```{r}

# Determine critical value, degrees of freedom calculated by number of permutations
qt(0.05, 10000) 

#' Credit: Volodymyr Orlov
#' modified by MSDS SMU
#' https://github.com/VolodymyrOrlov/MSDS6371/blob/master/shade.r
#' Draws a t-distribution curve and shades rejection regions
#' 
#' @param df degrees of freedom.
#' @param alpha significance level
#' @param h0 null hypothesis value
#' @param sides one of: both, left, right
#' @param t_calc calculated test statistics
#' @examples
#' shade(49, 0.05, 0, t_calc=1.1)
#' shade(91, 0.05, 0, t_calc=NULL, sides = 'right')
#' shade(7, 0.05, 0, t_calc=1.5, sides = 'left')
#' shade(7, 0.05, 0, t_calc=1.5, sides = 'both')

shade <- function(df, alpha, h0 = 0, sides='both', t_calc=NULL) {
  e_alpha = alpha
  if(sides == 'both'){
    e_alpha = alpha / 2
  }
  cv = abs(qt(e_alpha, df))
  curve(dt(x, df), from = -4, to = 4, ylab='P(x)', xaxt='n') 
  abline(v = 0, col = "black", lwd = 0.5)
  labels = h0
  at = 0
  if(sides == 'both' | sides == 'left'){
    x <- seq(-4, -abs(cv), len = 100) 
    y <- dt(x, df)
    polygon(c(x, -abs(cv)), c(y, min(y)), col = "blue", border = NA)
    lines(c(-cv, -cv), c(0, dt(-cv, df)), col = "black", lwd = 1)
    text(-cv - (4 - cv) / 2, 0.05, e_alpha)
    labels = c(round(-cv, 3), labels)
    at = c(-cv, at)
  }
  if(sides == 'both' | sides == 'right'){
    x <- seq(abs(cv), 4, len = 100)
    y <- dt(x, df)
    polygon(c(abs(cv), x), c(min(y), y), col = "blue", border = NA)
    lines(c(cv, cv), c(0, dt(cv, df)), col = "black", lwd = 1)
    text(cv + (4 - cv) / 2, 0.05, e_alpha)
    labels = c(labels, round(cv, 3))
    at = c(at, cv)
  }
  if(is.numeric(t_calc)){
    abline(v = t_calc, col = "red", lwd = 2)
    text(t_calc + 0.5, 0.2, t_calc, col = "red")
  }
  axis(1, at=at, labels=labels)
}
#The above defines the function shade. To use it, you must call it. More examples are in the comments above.
shade(14, 0.05, t_calc=-1.645006)

```

<h5>Wilcoxon Rank Sum Test</h5>
```{r}

wilcox.test(PercentLost ~ Action, data=loggingDF, conf.int=0.1, alternative='two.sided', exact=TRUE)

wilcox.test(actionU$PercentLost, actionL$PercentLost, exact=TRUE)
wilcox.test(actionU$PercentLost, actionL$PercentLost, exact=TRUE, alternative="l")
wilcox.test(actionU$PercentLost, actionL$PercentLost, exact=FALSE, alternative="g")
```
<h5>Permutation Test</h5>
```{r}
number_of_permutations <- 10000
xbarholder <- c()
counter <- 0
observed_difference <- mean(subset(loggingDF, Action=="L")$PercentLost) - mean(subset(loggingDF, Action=="U")$PercentLost)
for (i in 1:number_of_permutations) {
  scramble <- sample(loggingDF$PercentLost, 16)
  logged <- scramble[1:9]
  unlogged <- scramble[10:16]
  difference <- mean(logged) - mean(unlogged)
  xbarholder[i] <- difference
  if (difference >= observed_difference)
    counter <- counter + 1
}
hist(xbarholder, col="lightblue", main=paste("Differences of Means Under Null Distribution, n=", 16), xlab="Difference in Means")
abline(v=observed_difference, col="red", lwd=3)
p_value <- counter/number_of_permutations
p_value
```